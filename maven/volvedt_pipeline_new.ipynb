{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "volvedt_pipeline_new (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Josepholaidepetro/Volve_ML/blob/main/maven/volvedt_pipeline_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_LeyiRDbeVV"
      },
      "source": [
        "# Import relevant libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulSfBqb7Eg4K"
      },
      "source": [
        "import pickle\n",
        "import sys, os;    \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "# where the outputs are stored\n",
        "out_dir = str(os.getcwd())\n",
        "holdout = True"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSJbOJJaEnHG"
      },
      "source": [
        "#from google.colab import files\r\n",
        "#files.upload()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBeRsl0YEg4Z"
      },
      "source": [
        "def train_tranform(data_path):\n",
        "    \n",
        "    # Download the dataset and split into training and test data. \n",
        "    data = pd.read_csv(\"/content/train.csv\")\n",
        "    \n",
        "    # Preprocess\n",
        "    data.drop(['DEPTH', 'BS', 'RD', 'ROP', 'RM', 'DRHO'], axis=1, inplace=True)\n",
        "    \n",
        "    # If Nan, drop\n",
        "    data.dropna(inplace=True)\n",
        "    \n",
        "    # transform the RT to logarithmic\n",
        "    data['RT'] = np.log10(data['RT'])\n",
        "    \n",
        "    # perform a yeo-johnson transform of the train dataset\n",
        "    ptrain = PowerTransformer(method='yeo-johnson')\n",
        "    train_df_yj = ptrain.fit_transform(data.drop('DT', axis=1))\n",
        "    train_df_yj_norm = pd.DataFrame(train_df_yj, columns=data.columns.drop('DT'))\n",
        "    y_train = data['DT']\n",
        "    \n",
        "    #Save the train_data as a pickle file to be used by the predict component.\n",
        "    with open(f'{data_path}/train_tranform_data', 'wb') as f:\n",
        "        pickle.dump((train_df_yj_norm,  y_train), f)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TqJeXvnEg4b"
      },
      "source": [
        "train_tranform(out_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwMKdkg1Eg4c"
      },
      "source": [
        "def test_tranform(data_path):\n",
        "\n",
        "    # Download the dataset and split into training and test data. \n",
        "    data = pd.read_csv(\"/content/test.csv\")\n",
        "    \n",
        "    # Preprocess\n",
        "    data.drop(['DEPTH', 'BS', 'ROP', 'DRHO'], axis=1, inplace=True)\n",
        "    \n",
        "    # If Nan, drop\n",
        "    data.dropna(inplace=True)\n",
        "    \n",
        "    # transform the RT to logarithmic\n",
        "    data['RT'] = np.log10(data['RT'])\n",
        "    \n",
        "    # perform a yeo-johnson transform of the train dataset\n",
        "    ptest = PowerTransformer(method='yeo-johnson')\n",
        "    test_df_yj = ptest.fit_transform(data.drop('DT', axis=1))\n",
        "    test_df_yj_norm = pd.DataFrame(test_df_yj, columns=data.columns.drop('DT'))\n",
        "    y_test = data['DT']\n",
        "    \n",
        "    #Save the test_data as a pickle file to be used by the predict component.\n",
        "    with open(f'{data_path}/test_data', 'wb') as f:\n",
        "        pickle.dump((test_df_yj_norm,  y_test), f)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KUvrkcNEg4d",
        "outputId": "498b1397-f23c-4f1e-9d3d-b71c5b81664a"
      },
      "source": [
        "test_tranform(out_dir)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_data.py:2982: RuntimeWarning: divide by zero encountered in log\n",
            "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfNE48ELEg4f",
        "outputId": "a361144e-056a-4d14-87fc-b270c620d436"
      },
      "source": [
        "print(os.listdir())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'test_data', 'server.log', 'formation_eval.py', 'valid_data', 'Outlier_removal_train_valid', 'holdout', 'train.csv', 'test.csv', 'valid_tranform_train_data', 'Outlier_removal_train_data', 'train_tranform_data', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOFbYE78Eg4g"
      },
      "source": [
        "def Outlier_removal(data_path):\n",
        "\n",
        "    from sklearn.svm import OneClassSVM\n",
        "\n",
        "    # Load and unpack the train_data\n",
        "    with open(f'{data_path}/train_tranform_data','rb') as f:\n",
        "        train_data = pickle.load(f)\n",
        "    # Separate the train_df_yj_norm from y_train.\n",
        "    train_df_yj_norm,  y_train = train_data\n",
        "\n",
        "    # Method 4: One-class SVM\n",
        "    svm = OneClassSVM(nu=0.13)\n",
        "    yhat = svm.fit_predict(train_df_yj_norm)\n",
        "    mask = yhat != -1\n",
        "    train_df_svm = train_df_yj_norm[mask]\n",
        "    y_train_svm = y_train[mask]\n",
        "\n",
        "        \n",
        "    # prepare train data for modelling\n",
        "    X_train = train_df_svm.copy().drop(['label'], axis=1)\n",
        "    y_train = y_train_svm.copy()\n",
        "    \n",
        "    \n",
        "    #Save the train_data as a pickle file to be used by the predict component.\n",
        "    with open(f'{data_path}/Outlier_removal_train_data', 'wb') as f:\n",
        "        pickle.dump((X_train,  y_train), f)\n",
        "        \n",
        "    \n",
        "    #Save the train_data to be used for splitting as a pickle file to be used by the predict component.\n",
        "    with open(f'{data_path}/Outlier_removal_train_valid', 'wb') as f:\n",
        "        pickle.dump((train_df_svm.copy(), y_train_svm.copy()), f)\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGZSv-VSEg4h"
      },
      "source": [
        "Outlier_removal(out_dir)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KldqE1SNEg4h"
      },
      "source": [
        "def valid_tranform(data_path):\n",
        "    \n",
        "    # Load and unpack the full Outlier_removal_train_valid\n",
        "    with open(f'{data_path}/Outlier_removal_train_valid','rb') as f:\n",
        "        X_train,  y_train= pickle.load(f)\n",
        "    train_split = pd.concat([X_train.reset_index(drop=True),  y_train.reset_index(drop=True)], axis=1)\n",
        "    \n",
        "    # Separate the data into X_train and y_train.\n",
        "    X_train2 = train_split[train_split['label'] < 0].drop(['label', 'DT'], axis=1)\n",
        "    y_train2 = train_split[train_split['label'] < 0]['DT']\n",
        "    \n",
        "    # Separate the data into X_valid and y_valid.\n",
        "    X_valid = train_split[train_split['label'] > 0].drop(['label', 'DT'], axis=1)\n",
        "    y_valid = train_split[train_split['label'] > 0]['DT']\n",
        "    \n",
        "    #Save the valid_data as a pickle file to be used by the predict component.\n",
        "    with open(f'{data_path}/valid_data', 'wb') as f:\n",
        "        pickle.dump((X_valid,  y_valid), f)\n",
        "        \n",
        "    #Save the train_data as a pickle file to be used by the predict component.\n",
        "    with open(f'{data_path}/valid_tranform_train_data', 'wb') as f:\n",
        "        pickle.dump((X_train2,  y_train2), f)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0X-dNWDEg4h"
      },
      "source": [
        "valid_tranform(out_dir)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JzNHzfXEg4k"
      },
      "source": [
        "# The signature definition is defined by the input and output tensors,\n",
        "# and stored with the default serving key\n",
        "import tempfile\n",
        "MODEL_DIR = tempfile.gettempdir()\n",
        "version = 1\n",
        "export_path = os.path.join(MODEL_DIR, str(version))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAPSrHScINhM",
        "outputId": "7f2d3b71-52eb-4caf-b524-18774d1e602f"
      },
      "source": [
        "export_path, MODEL_DIR"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/tmp/1', '/tmp')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p0XVEg-iFnv"
      },
      "source": [
        "#  **TensorFlow Serving**\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvZFa62tiFq-"
      },
      "source": [
        "The first step in Tensorflow serving is to create and save Tensorflow objects ready to be put into production.\r\n",
        "Functions, embeddings or saved models are some of the objects that can be used as **servables**. \r\n",
        "\r\n",
        "In this workflow, we will be using the SavedModel method provided by tensorflow keras (tf.keras.models.save_model()). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adk37c1NhgYi"
      },
      "source": [
        "To load our trained model into TensorFlow Serving we first need to save it in SavedModel format. This will create a protobuf file in a well-defined directory hierarchy, and will include a version number. TensorFlow Serving allows us to select which version of a model, or \"servable\" we want to use when we make inference requests. Each version will be exported to a different sub-directory under the given path.\r\n",
        "\r\n",
        "The reason why we specify version is to keep track of previous models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHcroMINkFEX"
      },
      "source": [
        "Model building and saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RFwPrHnEg4l"
      },
      "source": [
        "def model_building(data_path, holdout, EXPORT_PATH):\n",
        "    import datetime\n",
        "    import pickle\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from keras.optimizers import SGD, Adam\n",
        "    \n",
        "    # Load and unpack the full Outlier_removal_train_data\n",
        "    with open(f'{data_path}/Outlier_removal_train_data','rb') as f:\n",
        "        Outlier_removal_train_data = pickle.load(f)\n",
        "    # Separate the X_train from y_train.\n",
        "    X_train,  y_train = Outlier_removal_train_data\n",
        "    \n",
        "    # Load and unpack the valid_tranform_train_data\n",
        "    with open(f'{data_path}/valid_tranform_train_data','rb') as f:\n",
        "        valid_tranform_train_data = pickle.load(f)\n",
        "    # Separate the X_train from y_train.\n",
        "    X_train_val,  y_train_val = valid_tranform_train_data\n",
        "    \n",
        "    # Load and unpack the valid_data\n",
        "    with open(f'{data_path}/valid_data','rb') as f:\n",
        "        valid_data = pickle.load(f)\n",
        "    # Separate the train_df_yj_norm from y_train.\n",
        "    X_valid,  y_valid = valid_data\n",
        "    \n",
        "    # Load and unpack the test_data\n",
        "    with open(f'{data_path}/test_data','rb') as f:\n",
        "        test_data = pickle.load(f)\n",
        "    # Separate the train_df_yj_norm from y_train.\n",
        "    X_test, y_test = test_data\n",
        "    \n",
        "    # Define the model using Keras\n",
        "    \n",
        "\n",
        "    tf.random.set_seed(1)\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(units =128, activation='relu', input_dim=X_train.shape[1]))\n",
        "    model.add(tf.keras.layers.Dense(units =128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units =256, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units =256, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units =1, activation='linear'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer = 'adam', loss='mean_squared_error')\n",
        "\n",
        "    \n",
        "    if holdout is False:\n",
        "        # Run a training job\n",
        "        model.fit(X_train, y_train, batch_size=20 , epochs=20 )\n",
        "    else:\n",
        "        # Run a training job\n",
        "        model.fit(X_train_val, y_train_val, batch_size=20 , epochs=20, validation_data=(X_valid, y_valid))\n",
        "        \n",
        "    tf.keras.models.save_model(\n",
        "    model,\n",
        "    export_path,\n",
        "    overwrite=True,\n",
        "    include_optimizer=True,\n",
        "    save_format=None,\n",
        "    signatures=None,\n",
        "    options=None\n",
        "    )\n",
        "    \n",
        "    #Save holdout\n",
        "    with open(f'{data_path}/holdout', 'wb') as f:\n",
        "        pickle.dump((holdout), f)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5m90DkoEg4l",
        "outputId": "097decc0-b0dc-4467-ff58-073d78a3ccdd"
      },
      "source": [
        "model = model_building(out_dir, holdout=True, EXPORT_PATH=export_path)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               1024      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 116,609\n",
            "Trainable params: 116,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "448/448 [==============================] - 2s 4ms/step - loss: 1104.4002 - val_loss: 99.7906\n",
            "Epoch 2/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 24.3513 - val_loss: 56.2135\n",
            "Epoch 3/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 14.9508 - val_loss: 56.0218\n",
            "Epoch 4/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 13.8794 - val_loss: 36.2231\n",
            "Epoch 5/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 13.2835 - val_loss: 35.8123\n",
            "Epoch 6/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 16.0545 - val_loss: 33.4594\n",
            "Epoch 7/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 13.7051 - val_loss: 28.7123\n",
            "Epoch 8/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 14.6252 - val_loss: 26.4951\n",
            "Epoch 9/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 14.7635 - val_loss: 20.1643\n",
            "Epoch 10/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 13.7013 - val_loss: 31.8428\n",
            "Epoch 11/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 12.5916 - val_loss: 35.9326\n",
            "Epoch 12/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 13.2906 - val_loss: 23.7062\n",
            "Epoch 13/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 13.7432 - val_loss: 25.6978\n",
            "Epoch 14/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 13.0923 - val_loss: 21.7264\n",
            "Epoch 15/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 12.7420 - val_loss: 22.2900\n",
            "Epoch 16/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 12.3571 - val_loss: 29.7708\n",
            "Epoch 17/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 12.2719 - val_loss: 17.2406\n",
            "Epoch 18/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 12.5491 - val_loss: 22.7586\n",
            "Epoch 19/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 13.9136 - val_loss: 27.0998\n",
            "Epoch 20/20\n",
            "448/448 [==============================] - 1s 3ms/step - loss: 12.1416 - val_loss: 19.7540\n",
            "INFO:tensorflow:Assets written to: /tmp/1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX4iSmBTkLOk"
      },
      "source": [
        "Check for the saved models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahw-GMkbOiYD",
        "outputId": "5ec063d2-c98f-433d-cc49-9d0a42662bea"
      },
      "source": [
        "print('\\nSaved model:')\r\n",
        "!ls -l {export_path}"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Saved model:\n",
            "total 136\n",
            "drwxr-xr-x 2 root root   4096 Jan  6 12:56 assets\n",
            "-rw-r--r-- 1 root root 129965 Jan  6 13:21 saved_model.pb\n",
            "drwxr-xr-x 2 root root   4096 Jan  6 13:21 variables\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jc_IQqmk-rV"
      },
      "source": [
        " What’s Saved ?\r\n",
        "\r\n",
        "\r\n",
        "The .pb is the MetaGraphDef which holds the graph structure. The variables folder holds your learned weights. The assets folder allow you to add external files that may be needed and assets.extra is a place libraries can add their assets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nZrEkiekRHD"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv14LUJnEg4n"
      },
      "source": [
        "def model_evaluate(data_path, EXPORT_PATH):\n",
        "    \n",
        "    import pickle\n",
        "    import sys, subprocess;\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    \n",
        "    file = f'{data_path}/holdout'\n",
        "    holdout = pickle.load(open(file, 'rb'))\n",
        "    \n",
        "    # Load the saved model\n",
        "    model = tf.keras.models.load_model(EXPORT_PATH)\n",
        "\n",
        "    # Load and unpack the test_data\n",
        "    with open(f'{data_path}/test_data','rb') as f:\n",
        "        test_data = pickle.load(f)\n",
        "    # Separate the X_test from y_test.\n",
        "    X_test, y_test = test_data\n",
        "    \n",
        "    \n",
        "    # Load and unpack the valid_data\n",
        "    with open(f'{data_path}/valid_data','rb') as f:\n",
        "        valid_data = pickle.load(f)\n",
        "    # Separate the train_df_yj_norm from y_train.\n",
        "    X_valid,  y_valid = valid_data\n",
        "    \n",
        "    if holdout is False:\n",
        "        #Evaluate the model and print the results\n",
        "        score = model.evaluate(X_test, y_test, verbose=0)\n",
        "        print(\"mse of Well 3: {}\".format(score))\n",
        "    else:\n",
        "        score = model.evaluate(X_valid,y_valid, verbose=0)\n",
        "        print(\"mse of Well 3: {}\".format(score))\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-99p_ZWEg4o",
        "outputId": "975ab7d2-8349-4216-b4c1-12847be83043"
      },
      "source": [
        "model_evaluate(out_dir, export_path)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mse of Well 3: 19.754016876220703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhkcncxTkWWX"
      },
      "source": [
        "**Examine your saved model**\r\n",
        "\r\n",
        "We'll use the command line utility saved_model_cli to look at the MetaGraphDefs (the models) and SignatureDefs (the methods you can call) in our SavedModel.    \r\n",
        "\r\n",
        "**About MetaGraphs and SignatureDefs**\r\n",
        "\r\n",
        "A MetaGraph is a dataflow graph, plus its associated variables, assets, and signatures. A MetaGraphDef is the protocol buffer representation of a MetaGraph.\r\n",
        "\r\n",
        "A SignatureDef defines the signature of a computation supported in a TensorFlow graph. SignatureDefs aim to provide generic support to identify inputs and outputs of a function and can be specified when building a SavedModel.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkN-PPAWEg4r",
        "outputId": "7ebaa7fb-b67b-4cc1-8066-a365c48beccb"
      },
      "source": [
        "!saved_model_cli show --dir {export_path} --all"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['dense_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 7)\n",
            "        name: serving_default_dense_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_4'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0106 13:21:24.756198 140596981389184 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 7), dtype=tf.float32, name=u'dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 7), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 7), dtype=tf.float32, name=u'dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 7), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 7), dtype=tf.float32, name=u'dense_input')\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 7), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 7), dtype=tf.float32, name=u'inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 7), dtype=tf.float32, name=u'dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          dense_input: TensorSpec(shape=(None, 7), dtype=tf.float32, name=u'dense_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-aCj0JNmifZ"
      },
      "source": [
        "**Serving your models us tf-serving**\r\n",
        "\r\n",
        "There are two ways to serve a mode using tf-serving:\r\n",
        "\r\n",
        "\r\n",
        "*   Using docker containers\r\n",
        "*   Running TensorFlow Serving natively\r\n",
        "\r\n",
        "For this problem, we will be using the second approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5CS5ecTniy8"
      },
      "source": [
        "**Add TensorFlow Serving distribution URI as a package source**\r\n",
        "\r\n",
        "We're preparing to install TensorFlow Serving using Aptitude since this Colab runs in a Debian environment. We'll add the tensorflow-model-server package to the list of packages that Aptitude knows about. \r\n",
        "\r\n",
        "Note that we're running as root.\r\n",
        "root is the user name or account that by default has access to all commands and files on a Linux or other Unix-like operating system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhEX3IeBEg4s",
        "outputId": "399b8db0-ddd3-4a63-c51b-316a94fd4552"
      },
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update # updates the list of packages in Aptitude"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2943  100  2943    0     0  98100      0 --:--:-- --:--:-- --:--:-- 98100\n",
            "OK\n",
            "Hit:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [277 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [53.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,273 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,140 kB]\n",
            "Fetched 4,996 kB in 3s (1,600 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "26 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hey-j7jRohEp"
      },
      "source": [
        "**Install TensorFlow Serving**\r\n",
        "\r\n",
        "This is all you need: !apt-get install tensorflow-model-server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-gYiX0FG_5t",
        "outputId": "f9939c7a-4911-47b8-e834-3fa2ba77012a"
      },
      "source": [
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tensorflow-model-server is already the newest version (2.4.0).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 26 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-dH7XiYo0kx"
      },
      "source": [
        "Start running TensorFlow Serving\r\n",
        "\r\n",
        "This is where we start running TensorFlow Serving and load our model. After it loads we can start making inference requests using REST. There are some important parameters:\r\n",
        "\r\n",
        "    rest_api_port: The port that you'll use for REST requests.\r\n",
        "    model_name: You'll use this in the URL of REST requests. It can be anything.\r\n",
        "    model_base_path: This is the path to the directory where you've saved your model.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-I9neecf6cx"
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynTSX_3YuEjQ",
        "outputId": "1d8fd845-ce51-4559-97e7-3e4c72a5be43"
      },
      "source": [
        "%%bash --bg \r\n",
        "nohup tensorflow_model_server \\\r\n",
        "  --rest_api_port=8701 \\\r\n",
        "  --model_name=log_model33 \\\r\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZGkNADn0L2T"
      },
      "source": [
        "So the first line here tells it to use the tensorflow model server, of course you would not include the bash magic cell while implementing it in practice i.e. the code line %bash --bg but because I am using Colab I have added that as Colab doesn’t provide me with a direct terminal.\r\n",
        "\r\n",
        "The second line here specifies the port on which you want to run the TF Model Server and is pretty straightforward too.\r\n",
        "\r\n",
        "A thing to notice in the third line is the --model_name, this will also appear in the URL on which you will be serving your models, so if you have multiple models at action managing your serving model URLs also becomes a lot easier.\r\n",
        "\r\n",
        "The last line here specifies that you want to enable logging and sometimes logs are just so helpful while debugging. I have personally used them quite a lot to figure out errors easily."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J4CCrXMHAGC",
        "outputId": "7e9ebd65-c878-4d20-d14c-15bf58cacb1f"
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-06 13:21:33.158424: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
            "2021-01-06 13:21:33.160271: I external/org_tensorflow/tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299995000 Hz\n",
            "2021-01-06 13:21:33.219271: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /tmp/1\n",
            "2021-01-06 13:21:33.226744: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 116182 microseconds.\n",
            "2021-01-06 13:21:33.228001: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /tmp/1/assets.extra/tf_serving_warmup_requests\n",
            "2021-01-06 13:21:33.228207: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: log_model33 version: 1}\n",
            "2021-01-06 13:21:33.229643: I tensorflow_serving/model_servers/server.cc:371] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "2021-01-06 13:21:33.230242: I tensorflow_serving/model_servers/server.cc:391] Exporting HTTP/REST API at:localhost:8701 ...\n",
            "[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPf2m3fkpS0J"
      },
      "source": [
        "# Creating a request to your model in TensorFlow Serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q_EHXkBp8a6"
      },
      "source": [
        "test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6y4fOd0PlWX"
      },
      "source": [
        "# Load and unpack the test_data\r\n",
        "with open(f'{out_dir}/test_data','rb') as f:\r\n",
        "    test_data = pickle.load(f)\r\n",
        "# Separate the X_test from y_test.\r\n",
        "X_test, y_test = test_data"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnwfl2Mip_kH"
      },
      "source": [
        "Converting data to json making a request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbrONaBgH2BQ"
      },
      "source": [
        "import json\n",
        "import requests\n",
        "def convert_to_json(test):\n",
        "    data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": test.values.tolist()})\n",
        "    return data"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_oaV4jFyOwE"
      },
      "source": [
        "data = convert_to_json(X_test[0:3])"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSHrd8HtEg4s"
      },
      "source": [
        "def predict(data):\n",
        "    headers = {\"content-type\": \"application/json\"}\n",
        "    json_response = requests.post('http://localhost:8701/v1/models/log_model33:predict', data=data, headers=headers)\n",
        "    predictions = json.loads(json_response.text)['predictions']\n",
        "    return predictions"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7-uab4iEg4x",
        "outputId": "f31f0670-a5e7-4e2c-ad26-9e61c3ccacd7"
      },
      "source": [
        "predict(data)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[97.62854], [97.681839], [97.9111328]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuLOBy74y5wn",
        "outputId": "d590252c-b04e-4e06-a463-6fc1c56b0707"
      },
      "source": [
        "y_test[:3]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    91.7473\n",
              "1    91.8580\n",
              "2    91.8593\n",
              "Name: DT, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mdinQui3uEl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}